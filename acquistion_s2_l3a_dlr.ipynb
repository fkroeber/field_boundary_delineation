{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info\n",
    "\n",
    "Script to download Level3A (WASP-generated) Sentinel2A data processed by the German Aerospace Centre.\n",
    "This data contains low-cloud/cloudfree, monthly averages of Sentinel2A scenes.\n",
    "\n",
    "Processing steps:\n",
    "* download tiles based on specified aoi, timeframe & bands\n",
    "* clipping tiles to aoi extent & creating a mosaic for each timestep and band\n",
    "\n",
    "What is not covered so far & may be improved in upcoming releases\n",
    "* consideration of quality control mask provided along with data for two reasons\n",
    "  + inaccuracy of the mask\n",
    "  + low significance of mask for clouds as processing chain removes almost all cloudy pixels\n",
    "\n",
    "But mask can be downloaded & clipped for AoI and then statistics be calculated to decide if it should be excluded (if above threshold value).\n",
    "Also visual inspection possible directly in script via plotting rbg image for region. Print statistics for each layer (on proprotion of masked pixels). Further idea: Script for downloading L2A data for specific AoI with cloud thresholding possibility (first look what is already provided on github in this regard). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "import minihit\n",
    "import numpy as np\n",
    "import os\n",
    "import rasterio\n",
    "import requests\n",
    "import shutil\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "from tqdm.notebook import tqdm\n",
    "from rasterio.mask import mask\n",
    "from rasterio.merge import merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### variables to set ###\n",
    "# download dir specifies existing folder to write scences to disk\n",
    "download_dir = os.path.join(os.getcwd(), \"test_data\", \"upper_rhine_area\", \"s2_l3a_data\")\n",
    "\n",
    "# aoi has to be specified as geojson\n",
    "# can be created online, e.g. via https://geojson.io\n",
    "aoi_geojson = os.path.join(os.path.dirname(download_dir), \"aoi.geojson\")\n",
    "\n",
    "# timeframe\n",
    "years = [2021]\n",
    "months = [x for x in range(4,10)]\n",
    "\n",
    "# bands\n",
    "bands = [\"B2\", \"B3\", \"B4\", \"B8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python310\\site-packages\\geopandas\\geodataframe.py:2196: UserWarning: `keep_geom_type=True` in overlay resulted in 4 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  return geopandas.overlay(\n",
      "C:\\Users\\felix\\AppData\\Roaming\\Python\\Python310\\site-packages\\geopandas\\geodataframe.py:2196: UserWarning: `keep_geom_type=True` in overlay resulted in 48 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  return geopandas.overlay(\n"
     ]
    }
   ],
   "source": [
    "# create dataset with utm tiles\n",
    "# download utm tile shp\n",
    "url = \"https://codeload.github.com/justinelliotmeyers/Sentinel-2-Shapefile-Index/zip/refs/heads/master\"\n",
    "wget.download(url, download_dir)\n",
    "with zipfile.ZipFile(os.path.join(download_dir, \"Sentinel-2-Shapefile-Index-master.zip\"), \"r\") as zip_ref:\n",
    "    zip_ref.extractall(download_dir)\n",
    "\n",
    "# read utm & delete copies on disk\n",
    "utm = gpd.read_file(os.path.join(download_dir, \"Sentinel-2-Shapefile-Index-master\", \"sentinel_2_index_shapefile.shp\"))\n",
    "shutil.rmtree(os.path.join(download_dir, \"Sentinel-2-Shapefile-Index-master\"))\n",
    "os.remove(os.path.join(download_dir, \"Sentinel-2-Shapefile-Index-master.zip\"))\n",
    "\n",
    "# restrict utm dataset to germany\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "germany = world[world[\"name\"] == \"Germany\"]\n",
    "\n",
    "# split utm tiles in overlapping areas\n",
    "_utm = utm.sjoin(germany).iloc[:,0:2].overlay(utm.sjoin(germany).iloc[:,0:2], how='union')\n",
    "_utm = _utm[_utm[\"Name_1\"] != _utm[\"Name_2\"]].dropna()\n",
    "\n",
    "_utm2 = utm.sjoin(germany).iloc[:,0:2].overlay(_utm, how='symmetric_difference')\n",
    "_utm2 = _utm2.rename(columns={\"Name\":\"Name_3\"})\n",
    "utm = _utm.append(_utm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33724/2520314395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# intersect aoi with utm to determine relevant utm tiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0maoi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maoi_geojson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mintersect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maoi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mset_utm_tiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintersect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name_1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name_2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintersect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Name_3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mset_utm_tiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtile\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset_utm_tiles\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utm' is not defined"
     ]
    }
   ],
   "source": [
    "# intersect aoi with utm to determine relevant utm tiles \n",
    "aoi = gpd.read_file(aoi_geojson)\n",
    "intersect = gpd.sjoin(aoi, utm)\n",
    "set_utm_tiles = [{x,y,z} for x,y,z in list(zip(intersect[\"Name_1\"], intersect[\"Name_2\"], intersect[\"Name_3\"]))]\n",
    "set_utm_tiles = [{x for x in tile if x==x} for tile in set_utm_tiles]\n",
    "\n",
    "# solve hitting set problem (a.k.a. set covering problem)\n",
    "# aim: filter absolute minimum of necessary utm tiles to cover aoi\n",
    "rc = minihit.RcTree(set_utm_tiles)\n",
    "rc.solve(prune=True, sort=False)\n",
    "utm_tiles = sorted(list(rc.generate_minimal_hitting_sets())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['32ULU']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utm_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e1c9e9400a46d486576639f6d67245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "constructing download urls & checking url validity:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL https://download.geoservice.dlr.de/S2_L3A_WASP/files/32/U/LU does not exist or cannot be queried\n",
      "--- Number/Availability of Scenes ---\n",
      "The current specification of aoi, timeframe and bands corresponds to a total of 24 individual tiles to be downloaded.\n",
      "Out of this 0 tiles (0%) are available on the server.\n",
      "\n",
      "--- Download volume ---\n",
      "Estimated download volume: ~5GB\n"
     ]
    }
   ],
   "source": [
    "# construction of download urls following the schema baseurl/utm_tile/year/month/band \n",
    "baseurl = \"https://download.geoservice.dlr.de/S2_L3A_WASP/files/\"\n",
    "download_urls = []\n",
    "\n",
    "for tile in tqdm(utm_tiles, desc='constructing download urls & checking url validity'):\n",
    "    # construct tiles\n",
    "    tile_url = os.path.join(baseurl, tile[0:2], tile[2:3], tile[3:]).replace('\\\\','/')\n",
    "    if requests.get(tile_url).status_code == 200:\n",
    "        # construct years\n",
    "        for year in years:\n",
    "            year_url = os.path.join(tile_url, str(year)).replace('\\\\','/')\n",
    "            if requests.get(year_url).status_code == 200:\n",
    "                # construct months\n",
    "                for month in months:\n",
    "                    month = \"0\" + str(month) if len(str(month))==1 else str(month)\n",
    "                    path_spec_month = \"SENTINEL2X_\" + str(year) + month + \"15-000000-000_L3A_T\" + tile + \"_C_V1-2\"\n",
    "                    month_url = os.path.join(year_url, path_spec_month).replace('\\\\','/')\n",
    "                    if requests.get(month_url).status_code == 200:\n",
    "                        # construct bands\n",
    "                        for band in bands:\n",
    "                            page_bands = requests.get(month_url)\n",
    "                            page_bands = BeautifulSoup(page_bands.content, \"html.parser\")\n",
    "                            path_spec_band = path_spec_month + \"_FRC_\" + band + \".tif\"\n",
    "                            if page_bands.find_all(\"a\", href=lambda x: x.startswith(path_spec_band)):\n",
    "                                band_url = os.path.join(month_url, path_spec_band).replace('\\\\','/')\n",
    "                                download_urls.append(band_url)\n",
    "                            else:\n",
    "                                print(f\"URL {band_url} does not exist or cannot be queried\")\n",
    "                    else:\n",
    "                        print(f\"URL {month_url} does not exist or cannot be queried\")\n",
    "            else:\n",
    "                print(f\"URL {year_url} does not exist or cannot be queried\")\n",
    "    else:\n",
    "        print(f\"URL {tile_url} does not exist or cannot be queried\")\n",
    "\n",
    "# evaluation of the availability and memory consumption for the selected tiles\n",
    "n_tiles = len(utm_tiles) * len(years) * len(months) * len(bands)\n",
    "\n",
    "memory_bands = []\n",
    "memory_bands.extend([240 for x in bands if x=='B8'])\n",
    "memory_bands.extend([200 for x in bands if x in ['B2','B3','B4']])\n",
    "memory_bands.extend([55 for x in bands if x in ['B5','B6','B7', 'B8A', 'B11', 'B12']])\n",
    "\n",
    "memory_all = n_tiles * sum(memory_bands) / len(bands)\n",
    "\n",
    "print(\"--- Number/Availability of Scenes ---\")\n",
    "print(f\"The current specification of aoi, timeframe and bands corresponds to a total of {n_tiles} individual tiles to be downloaded.\")\n",
    "print(f\"Out of this {len(download_urls)} tiles ({len(download_urls)/n_tiles:.0%}) are available on the server.\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"--- Download volume ---\")\n",
    "print(f\"Estimated download volume: ~{round(memory_all/1000) if memory_all>2500 else round(memory_all/1000,1)}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3940836dc92e4f37a89ab30f5056b40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "downloading data:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 853\u001b[1;33m                 \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    854\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13412/798356047.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     _ = list(tqdm(p.imap(download_scenes, download_urls, [download_dir for x in range(len(download_urls))]), \n\u001b[0m\u001b[0;32m     17\u001b[0m                   \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                   \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'downloading data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\multiprocess\\pool.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Python310\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# download of data\n",
    "# using multithreading to accelerate download\n",
    "# note: p.starmap stops download after each submitted chunk of tasks\n",
    "# note: using p.imap works & progress bar (tqdm) can still be displayed\n",
    "def download_scenes(url, dir):\n",
    "    import os\n",
    "    import sys\n",
    "    import wget\n",
    "    if not os.path.isfile(os.path.join(dir, url.split(\"/\")[-1])):\n",
    "        try:\n",
    "            wget.download(url, dir)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "with Pool(min(os.cpu_count(), 4)) as p:\n",
    "    _ = list(tqdm(p.imap(download_scenes, download_urls, [download_dir for x in range(len(download_urls))]), \n",
    "                  total=len(download_urls),\n",
    "                  desc='downloading data', \n",
    "                  smoothing=0.2))\n",
    "\n",
    "# in case of issues: use single core download\n",
    "# for url in tqdm(download_urls, desc='downloading data', smoothing=0.2):\n",
    "#     if not os.path.isfile(os.path.join(download_dir, url.split(\"/\")[-1])):\n",
    "#         wget.download(url, download_dir)\n",
    "\n",
    "print(f\"A total of {len(glob.glob(os.path.join(download_dir, 'SENTINEL2X*.tif')))} files is now present in specified download directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2af7ab59d74ae490f769c97a04be71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merging & masking of bands:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# procedure to mosaic and mask tiles per date & band\n",
    "downloaded_tiles = glob.glob(os.path.join(download_dir, 'SENTINEL2X*.tif'))\n",
    "tiles_per_date_band = [\"_\".join(x.split(\"\\\\\")[-1].split(\"_\")[:3]) + \"*\" + x.split(\"\\\\\")[-1].split(\"_\")[-1] for x in downloaded_tiles]\n",
    "tiles_per_date_band = list(set(tiles_per_date_band))\n",
    "\n",
    "for tiles in tqdm(tiles_per_date_band, desc=\"merging & masking of bands\"):\n",
    "\n",
    "    # open tiles\n",
    "    src_files_to_mosaic = []\n",
    "    for tile in glob.glob(os.path.join(download_dir, tiles)):\n",
    "        src = rasterio.open(tile)\n",
    "        src_files_to_mosaic.append(src)\n",
    "\n",
    "    # merge tiles\n",
    "    mosaic, out_trans = merge(src_files_to_mosaic)\n",
    "\n",
    "    out_meta = src.meta.copy()\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                    \"height\": mosaic.shape[1],\n",
    "                    \"width\": mosaic.shape[2],\n",
    "                    \"transform\": out_trans}\n",
    "                    )\n",
    "\n",
    "    out_dir = os.path.join(download_dir, tiles.replace(\"-000000-000\", \"\").replace(\"*\", \"_\"))\n",
    "    with rasterio.open(out_dir, \"w\", **out_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "    # mask tiles with aoi geojson\n",
    "    with rasterio.open(out_dir) as src:\n",
    "        masked_mosaic, out_trans2 = mask(src, aoi[\"geometry\"].to_crs(out_meta[\"crs\"].to_string()), crop=True)\n",
    "\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": masked_mosaic.shape[1],\n",
    "                        \"width\": masked_mosaic.shape[2],\n",
    "                        \"transform\": out_trans2}\n",
    "                        )\n",
    "\n",
    "    with rasterio.open(out_dir, \"w\", **out_meta) as dest:\n",
    "        dest.write(masked_mosaic)\n",
    "\n",
    "    #remove original data & keep only mosaic\n",
    "    for rasters in src_files_to_mosaic:\n",
    "        rasters.close()\n",
    "        \n",
    "    for tile in glob.glob(os.path.join(download_dir, tiles)):\n",
    "        os.remove(tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatibility with ecognition workflow\n",
    "# rename scenes\n",
    "downloaded_scenes = [x for x in glob.glob(os.path.join(download_dir, 'SENTINEL2X*.tif'))]\n",
    "\n",
    "for scene_path in downloaded_scenes:\n",
    "    scene = scene_path.split(\"\\\\\")[-1]\n",
    "    scene_date = scene.split(\"_\")[1]\n",
    "    scene_band = scene.split(\"_\")[-1].split(\".tif\")[0]\n",
    "    bandidx_to_name = {\"B2\": \"blue\", \"B3\": \"green\", \"B4\": \"red\", \"B8\": \"nir\"}\n",
    "    new_scene_name = f\"s2_l3a_{scene_date}_{bandidx_to_name[scene_band]}.tif\"\n",
    "    os.rename(scene_path, os.path.join(download_dir, new_scene_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output buffered aoi\n",
    "# aim: avoid border effects\n",
    "# means: 20m inwards buffer via Lambert Azimuthal Equal Area projection \n",
    "# aoi_ecognition = aoi.to_crs(crs=9821).buffer(-2000).to_crs(crs=4326)\n",
    "# aoi_ecognition_path = os.path.join(os.path.dirname(download_dir), \"aoi_ecognition.geojson\")\n",
    "# aoi_ecognition.to_file(aoi_ecognition_path, driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
